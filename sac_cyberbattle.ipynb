{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bb81b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0b5f4e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a097f15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /opt/miniconda/lib/python3.10/site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/miniconda/lib/python3.10/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack-data in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/miniconda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "get_ipython().system('pip install ipykernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf66eb9",
   "metadata": {},
   "source": [
    "# SAC Agent for CyberBattleIoT Environment\n",
    "\n",
    "This notebook demonstrates how to use a Soft Actor-Critic (SAC) agent with the CyberBattleIoT environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7eb23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afc0dd7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20213a84",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22c088a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Import CyberBattleIoT environment and other modules\n",
    "from final_project.iot_env import CyberBattleIoT\n",
    "from cyberbattle.agents.baseline import agent_dql\n",
    "from cyberbattle.agents.baseline.agent_dql import DeepQLearnerPolicy\n",
    "from final_project.iot_agents import DiscreteSACAgent, SafeSACAgent, ReplayBuffer\n",
    "import cyberbattle.agents.baseline.agent_wrapper as w\n",
    "import cyberbattle.agents.baseline.learner as learner\n",
    "from cyberbattle.agents.baseline.agent_wrapper import ActionTrackingStateAugmentation, AgentWrapper, Verbosity\n",
    "from typing import cast\n",
    "from cyberbattle._env.cyberbattle_env import CyberBattleEnv\n",
    "from cyberbattle._env.flatten_wrapper import (\n",
    "    FlattenObservationWrapper,\n",
    "    FlattenActionWrapper,\n",
    ")\n",
    "from stable_baselines3.common.type_aliases import GymEnv\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399260c7",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define helper functions for flattening state observations and training the SAC agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204423d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b183843c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Function to flatten dictionary state observations\n",
    "def flatten_state(obs_dict):\n",
    "    return np.concatenate([\n",
    "        np.atleast_1d(value).astype(np.float32)\n",
    "        for key, value in obs_dict.items()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b43d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcdfb686",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def sac_training(env, episodes=1000, replay_size=10000, batch_size=64, **kwargs):\n",
    "    # Get the correct state and action dimensions from the environment\n",
    "    state, _ = env.reset()\n",
    "    if isinstance(state, dict):\n",
    "        state_dim = len(flatten_state(state))\n",
    "    else:\n",
    "        state_dim = state.shape[0]\n",
    "\n",
    "    # Calculate total number of possible actions for the CyberBattle environment using env bounds\n",
    "    max_nodes = env.bounds.maximum_node_count\n",
    "    n_local_vulns = len(env.local_vulnerabilities)\n",
    "    n_remote_vulns = len(env.remote_vulnerabilities)\n",
    "\n",
    "    # Calculate action space size for each action type\n",
    "    connect_actions = max_nodes * max_nodes * len(env.ports)  # source * target * ports\n",
    "    local_exploit_actions = max_nodes * n_local_vulns  # nodes * local vulnerabilities\n",
    "    remote_exploit_actions = max_nodes * max_nodes * n_remote_vulns  # source * target * remote vulnerabilities\n",
    "    total_actions = connect_actions + local_exploit_actions + remote_exploit_actions\n",
    "\n",
    "    agent = DiscreteSACAgent(state_dim, total_actions, **kwargs)\n",
    "    memory = ReplayBuffer(replay_size)\n",
    "\n",
    "    rewards_history = []\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Convert state to tensor if it's a dictionary\n",
    "            if isinstance(state, dict):\n",
    "                state = flatten_state(state)\n",
    "\n",
    "            # Pass the environment to the act method\n",
    "            action = agent.act(state, env=env)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # Convert next_state to tensor if it's a dictionary\n",
    "            if isinstance(next_state, dict):\n",
    "                next_state = flatten_state(next_state)\n",
    "\n",
    "            memory.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "            if len(memory) > batch_size:\n",
    "                agent.update(memory, batch_size)\n",
    "\n",
    "        rewards_history.append(total_reward)\n",
    "        print(f\"Episode {ep}, Reward: {total_reward:.2f}\")\n",
    "\n",
    "    return agent, rewards_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaedf71c",
   "metadata": {},
   "source": [
    "## Set Up the Environment\n",
    "\n",
    "Create and configure the CyberBattleIoT environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77374ced",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[6]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade51a92",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "iot_env = CyberBattleIoT(\n",
    "    maximum_node_count=12,\n",
    "    maximum_total_credentials=10,\n",
    "    observation_padding=True,\n",
    "    throws_on_invalid_actions=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6d1a3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[7]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850d9b11",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out field _discovered_nodes\n",
      "Filtering out field _explored_network\n",
      "Filtering out field action_mask\n",
      "// MultiDiscrete flattened from [[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]] -> [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "// MultiDiscrete flattened from [4 4 4 4 4 4 4 4 4 4 4 4] -> [4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Wrap the environment\n",
    "flatten_action_env = FlattenActionWrapper(iot_env)\n",
    "flatten_obs_env = FlattenObservationWrapper(flatten_action_env, ignore_fields=[\n",
    "    \"_credential_cache\",\n",
    "    \"_discovered_nodes\",\n",
    "    \"_explored_network\",\n",
    "    \"action_mask\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c4a49",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03cc6e1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Cast to GymEnv\n",
    "env_as_gym = cast(GymEnv, flatten_obs_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c967b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7becef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Invalid entity index: Node index (9) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (7) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (6) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (7) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (7) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (2) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (5) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (3) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (7) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (3) is invalid; only 1 nodes discovered so far.\n",
      "WARNING:root:Invalid entity index: Node index (7) is invalid; only 1 nodes discovered so far.\n"
     ]
    }
   ],
   "source": [
    "# Check the environment\n",
    "check_env(flatten_obs_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e448bc9",
   "metadata": {},
   "source": [
    "## Set Hyperparameters\n",
    "\n",
    "Define the hyperparameters for training the SAC agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d7255",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08cc0845",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "EPISODES = 10\n",
    "MAX_STEPS = 1000\n",
    "GAMMA = 0.99  # discount factor\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "REPLAY_MEMORY_SIZE = 10000\n",
    "ALPHA = 0.2  # entropy coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83085f",
   "metadata": {},
   "source": [
    "## Train the SAC Agent\n",
    "\n",
    "Train the SAC agent on the CyberBattleIoT environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bebb7d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "054c6eb7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.bounds to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.bounds` for environment variables or `env.get_wrapper_attr('bounds')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/miniconda/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.local_vulnerabilities to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.local_vulnerabilities` for environment variables or `env.get_wrapper_attr('local_vulnerabilities')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CyberBattleIoT' object has no attribute 'local_vulnerabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m agent, rewards \u001b[38;5;241m=\u001b[39m \u001b[43msac_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_as_gym\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPISODES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREPLAY_MEMORY_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGAMMA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALPHA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36msac_training\u001b[0;34m(env, episodes, replay_size, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate total number of possible actions for the CyberBattle environment using env bounds\u001b[39;00m\n\u001b[1;32m     10\u001b[0m max_nodes \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mbounds\u001b[38;5;241m.\u001b[39mmaximum_node_count\n\u001b[0;32m---> 11\u001b[0m n_local_vulns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_vulnerabilities\u001b[49m)\n\u001b[1;32m     12\u001b[0m n_remote_vulns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(env\u001b[38;5;241m.\u001b[39mremote_vulnerabilities)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate action space size for each action type\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CyberBattleIoT' object has no attribute 'local_vulnerabilities'"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "agent, rewards = sac_training(\n",
    "    env_as_gym,\n",
    "    episodes=EPISODES,\n",
    "    replay_size=REPLAY_MEMORY_SIZE,\n",
    "    gamma=GAMMA,\n",
    "    alpha=ALPHA,\n",
    "    lr=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb2e31",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72778e1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce62e72",
   "metadata": {},
   "source": [
    "## Plot Training Results\n",
    "\n",
    "Visualize the training results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff633ff5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddf0a3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot the rewards\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rewards)\n",
    "plt.title('SAC Training Rewards')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084528c",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Agent\n",
    "\n",
    "Evaluate the trained agent on the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6a3e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fbd875",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Evaluate the agent\n",
    "def evaluate_agent(env, agent, num_episodes=5):\n",
    "    eval_rewards = []\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = agent.act(state, eval=True)  # Use deterministic actions for evaluation\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "        eval_rewards.append(total_reward)\n",
    "        print(f\"Evaluation Episode {ep}, Reward: {total_reward:.2f}\")\n",
    "\n",
    "    return eval_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bcdb6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f422a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "eval_rewards = evaluate_agent(env_as_gym, agent, num_episodes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34ef34",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f90e28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print average evaluation reward\n",
    "print(f\"Average evaluation reward: {np.mean(eval_rewards):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
